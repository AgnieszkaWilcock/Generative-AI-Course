# Introduction to Generative AI

Generative AI seems to have arrived suddenly but in fact it has a long gestation.  Here are a few moments of history.

* 1956, Artificial Intelligence (AI), ambition to create intelligent machines at the [Dartmouth Workshop](https://en.wikipedia.org/wiki/Dartmouth_workshop)
* 1997, Machine Learning (ML), _statistical_ learning from **data and predictions.**
* 2017, Deep Learning, a ML technique inspired by the wiring in our brains.  "Neurons" are connected into layers and the weights of the connections between neurons can be adjusted so that the neural net (NN) can "learn".
* 2021, Generative AI, create new content, which could be text, audio or video, given a prompt.  An extension of NNs using the transformer architecture.

## Large Language Models (LLMs)

A large language model is a type of AI program designed to understand, generate, and interact with human language. It's trained on vast amounts of text data.  It repatedly predicts the next word in a sentence to build a response to a prompt.  It can answer questions, write essays, and create code. 
Here are a couple of useful terms
* *prompt*  - input to the LLM, usuual a sentecnce or paragraph
* *completion* - the output (or response) from the LLM  

A large language model is a type of AI program designed to understand, generate, and interact with human language. It's trained on vast amounts of text data.  It repatedly predicts the next word in a sentence to build a response to a prompt.  It can answer questions, write essays, and create code. 
Here are a couple of useful terms
* *prompt*  - input to the LLM, usuual a sentecnce or paragraph
* *completion* - the output (or response) from the LLM  

